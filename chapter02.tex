\chapter{\uppercase{Background on Data-Consistent Inversion} \label{chapter:02}}

\section{Notation, Terminology, and Assumptions}
\subsection{Models and Parameters}
We begin by assuming that a (deterministic) model, denoted by $$\M (u, \param) = 0,$$ is specified to relate observable state variables $u$ to model inputs ({\em parameters}) denoted by the vector $\param\in\RP$.
The components $\param_\iparam$ may include parameters in either the model operator (e.g. a diffusion coefficient) or input data (e.g. the frequency of a sinusoidal source, initial, or boundary information).
We let $\pspace$ denote the set of all possible input parameters.
We assume $\pspace\subset\RP$ is equipped with a (dominating) measure, $\pmeas$ on the Borel $\sa$ $\pborel$, defining the measure space $\Pspace$.
The solution operator of the model $\M$ then defines a map taking $\param\in\pspace$ to a solution, denoted $u\lam$, to make explicit the dependence on $\param$, which is assumed to be unique.

However, in real experimental settings we are often unable to fully observe $u\lam$. 
Instead, we often only have access to some finite set of observable scalar quantities.
For example, in experiments involving the diffusion of heat, we can typically only record the temperature at some small number of pre-specified points in space-time where measurement devices can be positioned.

\subsection{Quantities of Interest}
Such observable values of $u\lam$ are mathematically modeled by functionals of the solution, denoted $\qoi_\idata: u\lam \to \RR$.
The collection of such functionals into a vector defines a {\em Quantity of Interest} (QoI) map.
Since the solution to the model depends on $\param$, so do the QoI, which motivates the notation
$$\qlam := \qoi( u\lam ) \in\RD,$$
to make this dependence on model parameters explicit.
Furthermore, this convention captures a realistic limitation of an experimental setting, where we may be able to control $\param$ in order to observe $\qlam$, but lack the ability to observe $u\lam$ directly.
The outputs of the QoI map $\qlam = \data$ are what we refer to as the \emph{data}.
Similarly, the range of the QoI defines the \emph{data space} $\dspace$, i.e.
$$\dspace = \qoi(\pspace) \subset \RD$$

We let $\qspace$ denote the set of possible QoI maps for which it is possible to collect experimental data.
For example, suppose we may record only a single temperature measurement at any of ten locations in space-time.
Then $\qspace$ is defined by ten possible QoI maps.
If we can record any two such measurements, then $\qspace$ is defined by $\binom{10}{2} = 45$ possible maps.
Observe that $\qspace$ could easily be uncountable, for example if we were not limited to the spatial locations (or time) at which we could record temperature measurements.
However, for simplicity, we will only discuss problems where $\qspace$ is finite.
In the event that we need to compare maps, we adopt the notation $\dspace_{\qoi}$ to emphasize that the data space depends on the choice of QoI map $\qoi$; when the context is clear, we drop the subscript.
The only assumption on $\qoi$ that we impose throughout this work is that of piecewise-differentiability.

\subsection{Chapter Outline}
First, to respect the order in which these results were researched and developed, we discuss set-based inversion.
In the interest of clarity of exposition, we have adapted the notation of a sample-based approach developed later to express the construction of the former.
Consequently, the references cited may require some work translating. Similarities and differences between the two approaches has heretofore avoided formal documentation, and this work serves to lay the groundwork for such a comparison. 

In this chapter, we discuss the issues that arise from the need to numerically approximate the solutions to our inverse problems but study the implications in \ref{sec:set-error} and \ref{sec:sample-error}.
Discussion of the impact of sample size are kept to a minimum in this chapter in the interest of restricting the scope of chapter \ref{chapter:03} to the implications for convergence of (consistent) solutions to \eqref{eq:inverse-problem}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Set-Based Inversion for Measures}\label{sec:ch02-set}
% Intro
\input{ch02/set_derivation}
\input{ch02/set_derivation_bayes}
% Numerical Approximation
\input{ch02/set_algorithm}
% Descriptions of Error
\input{ch02/set_error}
% Example
\input{ch02/identity_set}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section{Sample-Based Inversion for Measures}\label{sec:ch02-sample}

% Intro
\input{ch02/sample_derivation}
% Numerical Approximation
\input{ch02/sample_algorithm}
% Descriptions of Error
\input{ch02/sample_error}
% Example
Identity Map in two dimensions
\input{ch02/identity_sample}

[TK - Words]

\begin{equation}
\updatedP = \initialP \frac{\observedP}{\predictedP}
\end{equation}

\begin{equation}
\begin{split}
\dci\\
\dciP\\
\dciD
\end{split}
\end{equation}

In place of the ansatz, we have an initial distribution.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Software Contributions}\label{sec:ch02-software}
\input{ch02/software}


\section{Illustrative Examples}\label{sec:ch02-examples}
In some examples, an analytic, closed-form expression for the QoI map is used.
In these examples, term (E1) in Eq.~\eqref{eq:set-triangleineq} is identically zero.
Furthermore, since the probabilities we introduce on $\dspace$ in the numerical results are uniform and our maps linear, the densities can be described analytically with a characteristic function.
In this event, the solution $\paramP$ to the SIP is given exactly by a change of variables formula and it's support can be specified exactly.
By inverting characteristic functions, the solutions are also be members of this same family of functions if the choice of \emph{ansatz} (or \emph{initial density}) is taken to be uniform over $\pspace$.

Such simplifications in the examples considered here allow us to study the DCI method for a class of functions for which a solution is readily available, and serves as a requisite testing ground before advancing to more nuanced problem definitions.
In a sense, these are both ``unit'' (and ``regression'') tests for various aspects of the computational algorithms (and entire algorithms, respectively).

We present a brief overview of the factors that influence our practical ability to accurately approximate $\paramP$ and $\updated$ using finite sampling.

For the set-based approach discussed in \ref{sec:ch02-set}, it is desirable that $\ndiscs$ is chosen without respect to $\nsamps$ so that (E3) = $d(\PP_{\pspace, \ndiscs}, \paramP)$ from \ref{sec:set-error} is sufficiently small or eliminated entirely.
This amounts to saying that the decision about how to discretize the uncertainty in $\dspace$ is made a priori to cater to some problem specifications.
We choose to impose uniform distributions on $\dspace$ so that the set-valued analog to $\observed$ is perfectly described with $\ndiscs=1$.
This allows for a better comparison between the set- and sample-based approaches by eliminating this variable. 
Therefore, we focus our attention on the source of error introduced by the primary contribution of error in Eq.~\eqref{eq:set-triangleineq}:  discretizing the parameter space, which is represented by the term (E2) = $d(\PP_{\pspace, \ndiscs, \nsamps}, \PP_{\pspace, \ndiscs})$.
The number of samples fundamentally limits the characterization of events due to the resulting simple-function approximation of the density $d\paramP / d\pmeas$, which we compare to $\updated$ from the sample-based approach.

Since there is no error introduced from discretizing $\pspace$ in the sample-based approach from \ref{sec:ch02-sample}, the primary contribution of error in this approach comes from approximating the push-forward density in situations where an analytical $\predicted$ is not known.

\input{ch02/decay_set_vs_sample}

\input{ch02/heat_1drod_set_vs_sample}
