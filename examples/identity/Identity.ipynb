{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bet.sample as sample\n",
    "import bet.sampling.basicSampling as bsam\n",
    "import bet.calculateP.simpleFunP as sfnP\n",
    "import numpy as np\n",
    "import scipy.stats as sstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = 5,5\n",
    "plt.rcParams['font.size'] = 24\n",
    "# font sizes for labels and legends\n",
    "fsize_legend = 16\n",
    "fsize_label = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "numSamples = 10000\n",
    "# MC assumption on volumes\n",
    "MC_assumption = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(dimension)\n",
    "def model(input_samples):\n",
    "        return (I@input_samples.T).T\n",
    "sampler = bsam.sampler(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default random sample set is uniform over unit domain (normalized space)\n",
    "input_set = input_samples = bsam.random_sample_set('r',input_obj=dimension, num_samples=numSamples)\n",
    "param_ref = np.array([0.5, 0.5])\n",
    "input_set.set_reference_value(param_ref)\n",
    "\n",
    "# Estimate volumes of Voronoi cells associated with the parameter samples\n",
    "if MC_assumption is False:\n",
    "    input_samples.estimate_volume(n_mc_points=5E4)\n",
    "else:\n",
    "    input_samples.estimate_volume_mc()\n",
    "\n",
    "# input_set = bsam.regular_sample_set(input_obj=dimension, num_samples_per_dim=49)\n",
    "disc = sampler.compute_QoI_and_create_discretization(input_sample_set=input_set)\n",
    "Qref = disc.get_output().get_reference_value()\n",
    "print('Reference Value:', param_ref, 'maps to', Qref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_comparison(xi, yi, left, right,\n",
    "                       left_label='Approx', right_label='Exact', fdir='.'):\n",
    "    lambda_mesh = np.vstack([xi.flatten(),yi.flatten()]).T\n",
    "    if left.get_input().get_probabilities() is None:\n",
    "        zi_left = left.updated_pdf(lambda_mesh)\n",
    "    else:\n",
    "        png_left = left.get_input().get_probabilities()/left.get_input().get_volumes()\n",
    "        zi_left = png_left[left.get_input().query(lambda_mesh)[1]]\n",
    "\n",
    "    if right.get_input().get_probabilities() is None:\n",
    "        zi_right = right.updated_pdf(lambda_mesh)\n",
    "    else:\n",
    "        png_right = right.get_input().get_probabilities()/right.get_input().get_volumes()\n",
    "        zi_right = png_right[right.get_input().query(lambda_mesh)[1]]\n",
    "    max_ht = 30\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(12, 5), sharey=True)\n",
    "    # axes[0].pcolormesh(xi, yi, zi.reshape(xi.shape), shading='gouraud', cmap=plt.cm.viridis)\n",
    "    a00 = axes[0].contourf(xi, yi, zi_left.reshape(xi.shape), vmin=0, vmax=max_ht)\n",
    "    # axes[1].pcolormesh(xi, yi, zi_a.reshape(xi.shape), shading='gouraud', cmap=plt.cm.viridis)\n",
    "    a11 = axes[1].contourf(xi, yi, zi_right.reshape(xi.shape), vmin=0, vmax=max_ht)\n",
    "    axes[0].set_ylabel('$\\lambda_2$')\n",
    "    axes[1].set_xlabel('$\\lambda_1$')\n",
    "    axes[0].set_xlabel('$\\lambda_1$')\n",
    "\n",
    "    axes[0].annotate(left_label, (0.3, 0.7), fontsize=fsize_legend*1.5, c='w')\n",
    "    axes[1].annotate(right_label, (0.3, 0.7), fontsize=fsize_legend*1.5, c='w')\n",
    "    axes[0].axis('equal')\n",
    "    axes[1].axis('equal')\n",
    "    # fig.colorbar(a00, ax=axes[0])\n",
    "    # fig.colorbar(a11, ax=axes[1])\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.825, 0.125, 0.025, 0.75])\n",
    "    fig.colorbar(a00, cax=cbar_ax)\n",
    "    # plt.tight_layout()\n",
    "    savename = '%s/%s_N%d-vs-%s_N%d.png'%(fdir, left_label, left.check_nums(), right_label, right.check_nums())\n",
    "    savename = savename.replace('$','').replace('=','').replace(',','-').replace(' ','')\n",
    "    plt.savefig(savename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def udpated_png_conditional_comparison(disc, num=100,\n",
    "                                    condition_on=0.5,\n",
    "                                    label='approx',\n",
    "                                    fsize_label=24,\n",
    "                                    fsize_legend=16):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    num = 100\n",
    "    input_values_plotting = np.linspace(0.25,0.75,num)\n",
    "    # condition_on = 0.5\n",
    "    conditional = np.ones(num)*condition_on\n",
    "    condX = np.column_stack((conditional, input_values_plotting))\n",
    "    condY = np.column_stack((input_values_plotting, conditional))\n",
    "    ax.plot(input_values_plotting, \n",
    "            disc.updated_pdf(condX),\n",
    "            ls='-', lw=7,\n",
    "            label='${\\hat{\\pi}^{up}(\\lambda\\, |\\, \\lambda_2=%1.2f)}$'%condition_on)\n",
    "    ax.plot(input_values_plotting,\n",
    "            disc.updated_pdf(condY),\n",
    "            ls='--', lw=5,\n",
    "            label='${\\hat{\\pi}^{up}(\\lambda\\, |\\, \\lambda_1=%1.2f)}$'%condition_on)\n",
    "    plt.hlines(25,0.4,0.6, label='Analytical', lw=3, zorder=3)\n",
    "    plt.legend(loc=10, fontsize=fsize_legend)\n",
    "    plt.xlabel('$\\lambda_i$',fontsize=fsize_label)\n",
    "    plt.savefig('identity_1d_conditionals_%dE-2_N%d_%s.png'%(100*condition_on, disc.check_nums(), label),\n",
    "                bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Set-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bet.calculateP.simpleFunP as simpleFunP\n",
    "import bet.calculateP.calculateP as calculateP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_1 = disc.copy()\n",
    "simpleFunP.regular_partition_uniform_distribution_rectangle_size(\n",
    "        data_set=disc_1, Q_ref=Qref, rect_size=0.2,\n",
    "        cells_per_dimension = 1)\n",
    "calculateP.prob(disc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison's sake, we will also show \n",
    "# the impact of discretizing the output space\n",
    "disc_2 = disc.copy()\n",
    "simpleFunP.regular_partition_uniform_distribution_rectangle_size(\n",
    "        data_set=disc_2, Q_ref=Qref, rect_size=0.2,\n",
    "        cells_per_dimension = 2)\n",
    "calculateP.prob(disc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# png_1 = disc_1.get_input().get_probabilities()/disc_1.get_input().get_volumes()\n",
    "# png_2 = disc_2.get_input().get_probabilities()/disc_2.get_input().get_volumes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = input_set._values.T\n",
    "nbins = 50\n",
    "xmn, xmx = 0.25, 0.75\n",
    "ymn, ymx = 0.25, 0.75\n",
    "xi, yi = np.mgrid[xmn:xmx:nbins*1j, ymn:ymx:nbins*1j]\n",
    "lambda_mesh = np.vstack([xi.flatten(),yi.flatten()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_comparison(xi, yi, disc_1, disc_2,\n",
    "                   '$M=1, N=%d$'%(numSamples),\n",
    "                   '$M=4, N=%d$'%(numSamples), 'set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sample-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set distributions analytically.\n",
    "disc.set_initial(dist=sstats.uniform, loc=0, scale=1, gen=False)\n",
    "disc.set_observed(dist=sstats.uniform, loc=0.4, scale=0.2)\n",
    "# disc.compute_pushforward()\n",
    "# to see the impact of kernel density approximation, omit the following:\n",
    "# disc.set_predicted(dist=sstats.uniform, loc=0, scale=1)\n",
    "updated_pdf = disc.updated_pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D conditional Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udpated_png_conditional_comparison(disc, num=100,\n",
    "#                                 condition_on=0.5,\n",
    "#                                 label='approx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Predicted Distribution = No Error in Updated Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `BET`'s functionality to compute the updated density using analytical functions for all three components of the problem: initial, observed, and predicted.\n",
    "\n",
    "By creating a copy of our `discretization` object, we can edit our assumptions without affecting the instance we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_a = disc.copy()\n",
    "disc_a.get_input()._densities = None\n",
    "# disc_a.set_initial(num=int(1E3), gen=True)\n",
    "disc_a.set_predicted(dist=sstats.uniform, loc=0, scale=1)\n",
    "updated_pdf_a = disc_a.updated_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_b = disc.copy()\n",
    "disc_b.get_input()._densities = None\n",
    "disc_b.set_initial(num=int(1E3), gen=True)\n",
    "# disc_a.set_predicted(dist=sstats.uniform, loc=0, scale=1)\n",
    "updated_pdf_b = disc_b.updated_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_c = disc.copy()\n",
    "disc_c.get_input()._densities = None\n",
    "disc_c.set_initial(num=int(1E4), gen=True)\n",
    "# disc_a.set_predicted(dist=sstats.uniform, loc=0, scale=1)\n",
    "updated_pdf_c = disc_c.updated_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udpated_png_conditional_comparison(disc_a, num=100,\n",
    "#                                 condition_on=0.5,\n",
    "#                                 label='exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_comparison(xi, yi, disc_b, disc_c, '$N=$1000', '$N=$10000', 'samp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_comparison(xi, yi, disc, disc_a, '$N=$100', 'Analytical', 'samp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accept/Reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = disc.ratio_pdf()\n",
    "# acc = np.random.rand(disc.check_nums()) < r/r.max()\n",
    "# r_a = disc_a.ratio_pdf()\n",
    "# acc_a = np.random.rand(disc_a.check_nums()) < r_a/r_a.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot with accepted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn.kdeplot(x[acc], y[acc])\n",
    "# seaborn.kdeplot(x[acc_a], y[acc_a])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
