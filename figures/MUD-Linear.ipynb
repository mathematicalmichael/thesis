{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Linear Example: Dependence on Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy import stats, linalg\n",
    "import scipy as sp\n",
    "\n",
    "from mud.util import transform_setup, transform_linear_map, std_from_equipment, createRandomLinearPair, createRandomLinearProblem\n",
    "from mud.funs import mud_sol, map_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "plt.rcParams['font.size'] = 16\n",
    "fsize = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of Dimension for Various Choices of $\\Sigma_\\text{init}$\n",
    "We sequentially incorporate $D=1, \\dots , P$ dimensions into our QoI map and study the 2-norm between the true value that was used to generate the data and the analytical MUD/MAP points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randP(dim_input, dim_output, seed=27):\n",
    "    np.random.seed(seed)\n",
    "    lam_ref = np.random.rand(dim_input).reshape(-1,1)\n",
    "    A = np.random.randn(dim_output, dim_input)\n",
    "#     A = linalg.orth(A)\n",
    "#     Q, R = np.linalg.qr(A)\n",
    "#     A = Q\n",
    "#     A = np.random.rand(dim_output, dim_input)*2 - 1\n",
    "\n",
    "#     A = np.eye(dim_input)\n",
    "#     A = A[0:dim_output,:]\n",
    "    b = np.random.randn(dim_output).reshape(-1,1)\n",
    "#     b = np.random.rand(dim_output).reshape(-1,1)\n",
    "#     b = np.zeros(dim_output).reshape(-1,1)\n",
    "    y = A@lam_ref + b\n",
    "    return lam_ref, A, b, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input, dim_output = 100, 100\n",
    "initial_mean = np.zeros(dim_input).reshape(-1,1)\n",
    "lam_ref, A, b, d = randP(dim_input, dim_output)\n",
    "prefix='lin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numnonzero(x, tol=1E-4):\n",
    "    return len(x[abs(x)<tol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sols = {}\n",
    "dim_output\n",
    "tol_list = [10**(n) for n in np.linspace(-2,2,11)]\n",
    "std_list = [std_from_equipment(tol) for tol in tol_list]\n",
    "for std in std_list:\n",
    "    sols[std] = []\n",
    "    for o in range(0,dim_output+1, 1):\n",
    "        _A = A[0:o, :]\n",
    "        _b = b[0:o,:]\n",
    "        _d = d[0:o,:]\n",
    "        _mud = mud_sol(_A, _b, _d, initial_mean, std**2*np.eye(dim_input))\n",
    "        _map = map_sol(_A, _b, _d, initial_mean, std**2*np.eye(dim_input))\n",
    "        _pin = (np.linalg.pinv(_A)@(_d-_b)).reshape(-1,1)\n",
    "        sols[std].append((_mud, _map, _pin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = np.linalg.cond(A)*np.linalg.norm(lam_ref)\n",
    "c = 1\n",
    "err_mud_list = [[np.linalg.norm(_m[0] - lam_ref)/c for _m in sols[std]] for std in std_list ] # output_dim+1 values of _m\n",
    "err_map_list = [[np.linalg.norm(_m[1] - lam_ref)/c for _m in sols[std]] for std in std_list ]\n",
    "err_pin_list = [[np.linalg.norm(_m[2] - lam_ref)/c for _m in sols[std]] for std in std_list ]\n",
    "\n",
    "# c = np.linalg.cond(A)\n",
    "c = np.linalg.norm(A)\n",
    "err_Amud_list = [[np.linalg.norm(A@(_m[0] - lam_ref))/c for _m in sols[std]] for std in std_list ]\n",
    "err_Amap_list = [[np.linalg.norm(A@(_m[1] - lam_ref))/c for _m in sols[std]] for std in std_list ]\n",
    "err_Apin_list = [[np.linalg.norm(A@(_m[2] - lam_ref))/c for _m in sols[std]] for std in std_list ]\n",
    "\n",
    "# measure # of components that agree\n",
    "# err_mud_list = [[numnonzero(_m[0] - lam_ref) for _m in sols[std]] for std in std_list ]\n",
    "# err_map_list = [[numnonzero(_m[1] - lam_ref) for _m in sols[std]] for std in std_list ]\n",
    "# err_pin_list = [[numnonzero(_m[2] - lam_ref) for _m in sols[std]] for std in std_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.arange(1,1+dim_output,1), err_mud_list[0][0:-1]\n",
    "\n",
    "slope, intercept = (np.linalg.pinv(np.vander(x, 2))@np.array(y).reshape(-1,1)).ravel()\n",
    "regression = slope*x + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(x,std_list)\n",
    "ZU = np.array(err_mud_list)[:,0:100]\n",
    "ZA = np.array(err_map_list)[:,0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, np.log10(Y), ZU, alpha=0.5)\n",
    "ax.plot_surface(X, np.log10(Y), ZA, alpha=0.5)\n",
    "ax.set(ylabel='log10(Standard Deviation)', xlabel='Output Dimension', zlabel='Error')\n",
    "# ax.set(yscale='log')\n",
    "ax.view_init(15, 15)\n",
    "plt.savefig(f'{prefix}-surface-error.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, std in enumerate(std_list):\n",
    "    if idx>0: plt.annotate(f\"$\\sigma$={std:1.2E}\", (100, err_map_list[idx][-1]), fontsize=24)\n",
    "    _err_mud = err_mud_list[idx]\n",
    "    _err_map = err_map_list[idx]\n",
    "    _err_pin = err_pin_list[idx]\n",
    "    \n",
    "    plt.plot(x,_err_mud[:-1], label='mud', c='k', lw=10)\n",
    "    plt.plot(x,_err_map[:-1], label='map', c='r', ls='--', lw=5)\n",
    "    plt.plot(x,_err_pin[:-1], label='lsq', c='cyan', ls='--', lw=5)\n",
    "plt.plot(x,regression, c='g', ls='-')\n",
    "# plt.xlim(0,dim_output)\n",
    "plt.title(\"Convergence for Various $\\Sigma_{init} = \\sigma I$\", fontsize=1.25*fsize)\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.ylim(0, 7)\n",
    "# plt.ylim(1E-4, 5E-2)\n",
    "plt.ylabel(\"$||\\lambda_{ref} - \\lambda||$\", fontsize=fsize)\n",
    "plt.xlabel('Dimension of Output Space', fontsize=fsize)\n",
    "plt.legend(['mud', 'map', 'least squares'], fontsize=fsize)\n",
    "plt.annotate(f'Slope={slope:1.4f}', (4,4), fontsize=24)\n",
    "plt.savefig(f'{prefix}-convergence-dimension.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "These results appear to hold for random $A$'s generated with uniform and normal distributions, and even hold for $A=I$ (which actually fairs worse for the MAP solution, as do orthogonal maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, std in enumerate(std_list):\n",
    "    _err_mud = err_Amud_list[idx]\n",
    "    _err_map = err_Amap_list[idx]\n",
    "    _err_pin = err_Apin_list[idx]\n",
    "    \n",
    "    plt.plot(np.arange(0, 1+dim_output),_err_mud[:], label='mud', c='k', lw=10)\n",
    "    plt.plot(np.arange(0, 1+dim_output),_err_map[:], label='map', c='r', ls='--', lw=5)\n",
    "    plt.plot(np.arange(0, 1+dim_output),_err_pin[:], label='lsq', c='cyan', ls='--', lw=5)\n",
    "# plt.plot(x,regression, c='g', ls='-')\n",
    "# plt.xlim(0,dim_output)\n",
    "plt.title(\"Convergence for Various $\\Sigma_{init} = \\sigma I$\", fontsize=1.25*fsize)\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# plt.ylim(0, 6)\n",
    "# plt.ylim(1E-4, 5E-2)\n",
    "plt.ylabel(\"$\\\\frac{||A (\\lambda_{ref} - \\lambda) ||}{||A||}$\", fontsize=fsize)\n",
    "plt.xlabel('Dimension of Output Space', fontsize=fsize)\n",
    "# plt.legend(['mud', 'map', 'least squares'], fontsize=fsize)\n",
    "# plt.annotate(f'Slope={slope:1.4f}', (4,4), fontsize=24)\n",
    "plt.savefig(f'{prefix}-convergence-dimension-out.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_mud_mismatch = np.vstack( [ [np.linalg.norm(_err_pin[n] - _err_mud[n]) for n in range(dim_input)] for _err_pin, _err_mud in zip(err_pin_list, err_mud_list)])\n",
    "plt.plot(x, pin_mud_mismatch.T, c='k')\n",
    "plt.xlabel('Dimension', fontsize=fsize)\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('$||\\lambda_{mud} - \\lambda_{lsq}||$', fontsize=fsize)\n",
    "plt.title(\"MUD $\\\\approx$ Least Squares\", fontsize=1.25*fsize)\n",
    "plt.savefig(f\"{prefix}-mud-leastsquares-error.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = []\n",
    "tol = 0.1\n",
    "std = std_from_equipment(tol)\n",
    "std = 1\n",
    "for o in range(dim_output):\n",
    "    _A = A[0:o, :]\n",
    "    _b = b[0:o,:]\n",
    "    _y = y[0:o,:]\n",
    "    _mud = mud_sol(_A, _b, _y, initial_mean, std**2*np.eye(dim_input))\n",
    "    _map = map_sol(_A, _b, _y, initial_mean, std**2*np.eye(dim_input))\n",
    "    sol.append((_mud, _map))\n",
    "\n",
    "err_mud = [np.linalg.norm(_m[0] - lam_ref) for _m in sol] \n",
    "err_map = [np.linalg.norm(_m[1] - lam_ref) for _m in sol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_mud, label='mud', c='k')\n",
    "plt.plot(err_map, label='map', c='r', ls='--')\n",
    "plt.title(f\"$L^2$ Convergence for $\\sigma = {std:1.4E}$\")\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.xlabel('Dimension')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 100\n",
    "lam_true = np.array([[0.5, 0.5]]).reshape(-1,1)\n",
    "M, data = createRandomLinearPair(lam_true, num_observations=100, std=0.001, repeated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(M@lam_true - data)), np.linalg.norm(M@lam_true - data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(S), M@lam_true, c='r')\n",
    "plt.plot(np.arange(S), data)\n",
    "plt.plot(np.arange(S), np.mean(data)*np.ones(S), '--', c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = transform_linear_map(M, data, 0.001)\n",
    "print(S, A, b)\n",
    "np.mean(np.abs(A@lam_true + b)), np.linalg.norm(A@lam_true + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qoi = 1\n",
    "num_obs = 1000\n",
    "num_trials = 500\n",
    "predictions = []\n",
    "for _ in range(num_trials):\n",
    "    operator_list, data_list, std_list = createRandomLinearProblem([0.5, 0.5], num_qoi, num_obs, 0.001, repeated=True)\n",
    "    A, b = transform_setup(operator_list, data_list, std_list)\n",
    "    predictions.append(A@lam_true + b)\n",
    "samples = [p[0,0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples, 20, density=True)\n",
    "x = np.linspace(-3,3,1000)\n",
    "y = stats.norm.pdf(x)\n",
    "plt.title(f\"Predictions from {num_trials} Random Linear Problems\")\n",
    "plt.plot(x,y)\n",
    "n = stats.normaltest(samples)\n",
    "plt.annotate(f\"Normal Test\\n  Statistic: {n[0]:1.4f}\\n  p-value : {n[1]:1.4f}\", (-3.25,0.3))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity - Different Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = 2\n",
    "num_qoi = 1 # fix at 1 for this example\n",
    "num_obs = 1000\n",
    "num_trials = 100\n",
    "predictions = []\n",
    "std = 0.001\n",
    "std_list = [std]*num_obs\n",
    "reference_point = [0.5, 0.5]\n",
    "operator_list = [createRandomLinearMap(dim_input, num_obs, repeated=True) for _ in range(num_qoi)]\n",
    "for _ in range(num_trials):    \n",
    "    data_list = [createNoisyReferenceData(M, reference_point, std) for M in operator_list]\n",
    "    A, b = transform_setup(operator_list, data_list, std_list)\n",
    "    predictions.append(A@lam_true + b)\n",
    "samples = [p[0,0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples, 20, density=True)\n",
    "x = np.linspace(-3,3,1000)\n",
    "y = stats.norm.pdf(x)\n",
    "plt.title(f\"Predictions from {num_trials} Data Streams for a Random Linear Map\")\n",
    "plt.plot(x,y)\n",
    "n = stats.normaltest(samples)\n",
    "plt.annotate(f\"Normal Test\\n  Statistic: {n[0]:1.4f}\\n  p-value : {n[1]:1.4f}\", (-3.25,0.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Inputs/Outputs to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_true = [0.5, 0.5]\n",
    "dim_input = 2\n",
    "num_observations = 100\n",
    "# M = createRandomLinearMap(dim_input, num_observations, repeated=True)\n",
    "sigma = std_from_equipment(tolerance=0.1, probability=0.99)\n",
    "M, data = createRandomLinearPair(lam_true, num_observations, sigma, repeated=True)\n",
    "def makeLinearModel(M):\n",
    "    num_observations = M.shape[0]\n",
    "    def model(lam = np.array([lam_true]) ):\n",
    "        response     = (M@lam.T).T\n",
    "        if response.shape[0] == 1:\n",
    "            return response.ravel() # this allows support for simpler 1D plotting.\n",
    "        else:\n",
    "            return response\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = makeLinearModel(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model() - data.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = 100\n",
    "reference_point = np.random.rand(dim_input).reshape(-1,1)\n",
    "num_qoi = 100\n",
    "num_observations_list = [1000]*num_qoi\n",
    "std_list = [sigma]*num_qoi\n",
    "initial_mean = np.zeros(dim_input).reshape(-1,1)\n",
    "initial_cov = np.eye(dim_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_list, data_list, std_list = createRandomLinearProblem(reference_point, num_qoi,\n",
    "                                      num_observations_list, std_list,\n",
    "                                      dist='normal', repeated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = transform_setup(operator_list, data_list, std_list)\n",
    "pred_sol = (A@reference_point + b).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mud_pt = mud_sol(A,b, initial_mean, initial_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(mud_pt - reference_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_sol, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sol.mean(), pred_sol.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Measurements / Reference Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FIXED PARAMETERS - DEFINE YMUR EXPERIMENT #####\n",
    "sigma      = 0.001\n",
    "\n",
    "################\n",
    "################\n",
    "model           = makeLinearModel(M)\n",
    "qoi_true        = model() # no args evaluates true param\n",
    "sigma2          = sigma**2 # fixed noise level in the data\n",
    "# d             = createNoisyReferenceData(M, lam_true, sigma)\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input / output sets\n",
    "\n",
    "We fix our exploratory samples of the parameter space $\\Lambda$ for all experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1E4\n",
    "lam = np.random.rand(int(num_samples),2)\n",
    "a = np.argsort(lam.ravel())\n",
    "qoi = model(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qoi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Inverse Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bet.sample as samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mud_problem(lam, qoi, sd=sigma, num_obs=None, qoi_true=qoi_true):\n",
    "    try:\n",
    "        dim_input = lam.shape[1]\n",
    "    except IndexError:\n",
    "        dim_input = 1\n",
    "\n",
    "    try:\n",
    "        dim_output = qoi.shape[1]\n",
    "    except IndexError:\n",
    "        dim_output = 1\n",
    "\n",
    "    if num_obs is None:\n",
    "        num_obs = dim_output\n",
    "    elif num_obs < 1:\n",
    "        raise ValueError(\"num_obs must be >= 1\")\n",
    "    elif num_obs > dim_output:\n",
    "        raise ValueError(\"num_obs must be <= dim(qoi)\")\n",
    "\n",
    "    i_set = samp.sample_set(dim_input)\n",
    "    i_set.set_domain(np.array([[0,1]*dim_input]))\n",
    "    \n",
    "    i_set.set_values(lam)\n",
    "    o_set = samp.sample_set(dim_output)\n",
    "    o_set.set_values(qoi)\n",
    "    d = samp.discretization(i_set, o_set)\n",
    "    data = qoi_true[0:num_obs] + np.random.randn(num_obs)*sd\n",
    "    \n",
    "    # TMDM generalize\n",
    "    d.set_initial(dist=sp.stats.distributions.uniform(loc=0,scale=1), gen=False)\n",
    "    # needed if changing dimensions around until fix is made in BET\n",
    "#     d._output_probability_set = None # will throw warning\n",
    "    d._output_probability_set = samp.sample_set(num_obs)\n",
    "    d.data_driven(data=data, std=sd, inds=list(range(0,num_obs)))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens as we take more observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make MUD solutions for successive inclusions of measurements\n",
    "\n",
    "We take repeated trials (draws of noise polluting our data) to study the sensitivity to individual experiments as a function of number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_sensor_list = np.arange(num_observations) + 1\n",
    "experiments = {}\n",
    "solutions = {}\n",
    "num_trials = 5 # realizations of synthetic data\n",
    "# num_sensors_plot_conv = num_sensor_list[4::5]\n",
    "num_sensors_plot_conv = [1, 5, 10, 25, 50, 100]\n",
    "for ns in num_sensors_plot_conv:\n",
    "    discretizations = []\n",
    "    mud_solutions = []\n",
    "    for t in range(num_trials):\n",
    "        np.random.seed(21+t)\n",
    "        _d = mud_problem(lam, qoi, sd=sigma, num_obs=ns)\n",
    "        discretizations.append(_d)\n",
    "        mud_solutions.append(_d.mud_point())\n",
    "    experiments[ns] = discretizations\n",
    "    solutions[ns] = mud_solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract means and variances from repeated trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "variances = []\n",
    "for ns in num_sensors_plot_conv:\n",
    "    mud_solutions = solutions[ns]\n",
    "    discretizations = experiments[ns]\n",
    "    _data = np.array([ _d.get_data() for _d in discretizations])\n",
    "    err = np.abs((M@np.array(mud_solutions).T).T[:,0] - (M@lam_true)[0]) # truth\n",
    "    mean_mud_sol = np.mean(err)\n",
    "    var_mud_sol = np.var(err)\n",
    "    means.append(mean_mud_sol)\n",
    "    variances.append(var_mud_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the accuracy + precision change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_sensors_plot_conv, means, label='mean', c='xkcd:blue')\n",
    "plt.plot(num_sensors_plot_conv, variances, label='variance', c='xkcd:red')\n",
    "plt.plot(num_sensors_plot_conv, 0.01*np.power(np.array(num_sensors_plot_conv), -1/2)/10, label='~ $N^{-1/2}$', ls='--', c='xkcd:blue')\n",
    "plt.plot(num_sensors_plot_conv, 1E-7/np.array(num_sensors_plot_conv), label='~ $N^{-1}$', ls='--', c='xkcd:red')\n",
    "\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Number of Measurements')\n",
    "plt.ylabel('Mean Normed Error in Prediction')\n",
    "plt.title(f\"Convergence for N={lam.shape[0]} parameter samples\")\n",
    "plt.savefig('lin_convergence_mud_obs.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement Error\n",
    "\n",
    "Fixed number of sensors, varying the quality of equipment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sd_err = []\n",
    "sd_var = []\n",
    "sd_vals = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "num_trials = 10\n",
    "num_obs_meas = 10\n",
    "for sd in sd_vals:\n",
    "    temp_err = []\n",
    "    for t in range(num_trials):\n",
    "        d = mud_problem(lam, qoi, sd=sd, qoi_true=qoi_true, num_obs=num_obs_meas)\n",
    "        mud_point = d.mud_point()\n",
    "#         temp_err.append(np.abs((M@mud_point)[0] - (M@lam_true)[0])) # truth\n",
    "        temp_err.append(np.abs((M@mud_point)[0] - d.get_data())) # observed\n",
    "    sd_err.append(np.mean(temp_err))\n",
    "    sd_var.append(np.var(temp_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sd_vals, sd_err, label='mean', c='xkcd:red')\n",
    "plt.plot(sd_vals, sd_var, label='variance', c='xkcd:blue')\n",
    "plt.plot(sd_vals, np.power(np.array(sd_vals), 2), label='$\\sigma^2$', ls='--', c='xkcd:blue')\n",
    "plt.plot(sd_vals, np.power(np.array(sd_vals), 1), label='$\\sigma$', ls='--',  c='xkcd:red')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.xlabel(\"Standard deviation\")\n",
    "plt.title(f\"Impact of Measurement Noise on MUD Error for S={num_obs_meas}\")\n",
    "plt.savefig('lin_convergence_mud_std.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
