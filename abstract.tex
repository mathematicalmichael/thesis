This work is concerned with presenting novel developments in the solution of stochastic inverse problems in a measure-theoretic framework which leverages push-forward and pull-back measures.
Previous work focused on transforming distributions based on the differences between push-forward and observed measures rather than the popular Bayesian approach of updating prior beliefs with likelihood functions.
The primary contributions herein revolve around extending the Data-Consistent Inversion framework to address problems that seek to identify a single ``true'' parameter from the aggregation and use of noisy data. 
Prior work was developed around problems that quantified parameter variability inherent to natural processes such as manufacturing or experimental setup, leaving no need to presume the existence of a single parameter value that explained variations in observational data.
However, many scientific problems are inherently grounded in such a belief, and so we are motivated to extend the Data-Consistent Inversion framework to address such scenarios in hopes that it can provide feasible alternatives to Bayesian Likelihood approaches.

As such, this work sits at the intersection of applied mathematics, science, and computation.
The scientific ``laboratory'' in which we perform our (simulated) experiments is the computer. 
Since computation plays such an integral part in the process of answering the aforementioned questions, a considerable amount of attention is also devoted to addressing software development. 
A novel method whose implementation is difficult to use is unlikely to see widespread adoption, so in the interest of making our work as accessible as possible, a lot of non-mathematical content is presented.
This work will demonstrate in detail how the open-source tools we developed were built and delivered to the scientific community. 