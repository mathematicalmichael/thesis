{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUD Point for Linear Mappings\n",
    "\n",
    "We want to compute what is the maximum-updated-density (MUD) point for the data-consistent inversion updated posterior. We do this for the simple case of linear maps, introducing assumptions as we go to allow for interpretability.\n",
    "\n",
    "We start with writing the form for the MUD point as a maximization problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\max_{\\lambda}{\\pi^{up}(\\lambda)}=\\max_{\\lambda}\\left\\{\\pi^{init}(\\lambda)\\cdot\\dfrac{\\pi^{data}\\left(Q(\\lambda)\\right)}{\\pi^{pf}\\left(Q(\\lambda)\\right)}\\right\\}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "## For all one-to-one maps, the updated PDF is exactly the same as the data-generating PDF\n",
    "First suppose that $\\lambda$ is a univariate random variable and $Q(\\lambda)$ is a linear map from $\\mathbb{R}\\rightarrow\\mathbb{R}$: \n",
    "\n",
    "$$Q(\\lambda)=A\\lambda+b.$$\n",
    "\n",
    "For such a linear transformation, we can compute the push-forward of $\\pi^{init}$ through the map $Q$ very easily.\n",
    "\n",
    "\\begin{align}\n",
    "\\pi^{pf}(q)&=\\frac{1}{A}\\pi^{init}\\left(\\frac{q-b}{A}\\right)=\\frac{1}{A}\\pi^{init}\\left(\\lambda\\right)\n",
    "\\end{align}\n",
    "\n",
    "What does this mean?\n",
    "\n",
    "This essentially means that the updated distribution will look like:\n",
    "\n",
    "\\begin{align}\n",
    "\\pi^{up}(\\lambda)&=\\pi^{init}(\\lambda)\\cdot\\dfrac{\\pi^{data}\\left(Q(\\lambda)\\right)}{\\frac{1}{A}\\pi^{init}\\left(\\lambda\\right)} \\\\[2ex]\n",
    "&=A\\cdot\\pi^{data}\\left(Q(\\lambda)\\right) \\\\[2ex]\n",
    "\\end{align}\n",
    "\n",
    "Let $\\pi^{gen}(\\lambda)$ be the true data generating pdf of $\\lambda$. The using transformations, we will get that:\n",
    "\n",
    "\\begin{align}\n",
    "\\pi^{up}(\\lambda)&=A\\cdot\\pi^{data}\\left(Q(\\lambda)\\right)=A\\cdot\\frac{1}{A}\\pi^{gen}\\left(\\lambda\\right)=\\pi^{gen}\\left(\\lambda\\right) \\\\[2ex]\n",
    "\\end{align}\n",
    "\n",
    "In other words, the updated posterior will be exactly the data-generating pdf. Exactly. This means that all statistical moments will be exactly the same, so there is nothing to prove here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose $Q(\\lambda)$ is any one-to-one function with inverse $Q^{-1}(q)$. Then we can compute the push-forward for the random variable $\\lambda$ exactly:\n",
    "\n",
    "\\begin{align}\n",
    "\\pi^{pf}(q)&=\\pi^{init}\\left(Q^{-1}(q)\\right)\\cdot \\left|\\dfrac{dQ^{-1}}{dq}\\right|=\\pi^{init}\\left(\\lambda\\right)\\left|\\dfrac{dQ^{-1}}{dq}\\right|\n",
    "\\end{align}\n",
    "\n",
    "Then we will have the same situation as for a linear map:\n",
    "\n",
    "\\begin{align}\n",
    "\\pi^{up}(\\lambda)&=\\pi^{init}(\\lambda)\\cdot\\dfrac{\\pi^{data}\\left(Q(\\lambda)\\right)}{\\pi^{init}\\left(\\lambda\\right)\\left|\\dfrac{dQ^{-1}}{dq}\\right|} \\\\[2ex]\n",
    "&=\\left|\\dfrac{dQ^{-1}}{dq}\\right|^{-1}\\cdot\\pi^{data}\\left(Q(\\lambda)\\right) \\\\[2ex]\n",
    "&=\\left|\\dfrac{dQ^{-1}}{dq}\\right|^{-1}\\left|\\dfrac{dQ^{-1}}{dq}\\right|\\cdot\\pi^{gen}\\left(\\lambda\\right) \\\\[2ex]\n",
    "&=\\pi^{gen}\\left(\\lambda\\right) \\\\[2ex]\n",
    "\\end{align}\n",
    "\n",
    "Which again means that there is nothing to prove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KEY TAKEAWAY:\n",
    "For any one-to-one map $Q$, all statistics from the updated pdf will be the same as if drawn from the data-generating pdf, **regardless of the initial distribution**. This means that the only errors that will occur in the calculation of statistics on $\\lambda$ will be from approximations of either the data pdf or the push-forward pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Maps without an Inverse:\n",
    "\n",
    "Suppse we have a map that is linear but not one-to-one. Let $\\lambda$ be a multivariate random variable in $\\mathbb{R}^M$ and $Q(\\lambda):\\mathbb{R}^M\\rightarrow\\mathbb{R}$, where $Q$ is linear. In particular, suppose $Q(\\lambda)$ is:\n",
    "\n",
    "\\begin{align}\n",
    "Q(\\lambda)=a^T\\lambda\n",
    "\\end{align}\n",
    "\n",
    "Let $q\\sim N(\\nu,\\sigma_\\nu^2)$, in other words, the data being analyzed is normally distributed.\n",
    "\n",
    "Since our data is normally distributed, I suspect it will be beneficial to choose a initial distribution from a family of distributions such that the push forward of our initial distribution will also be normally distributed. Because our map is a weighted sum of random variable $\\lambda_i$, it makes sense to choose an initial distribution to be normal, since we know that a sum of independent normally distributed random variables is normal. \n",
    "\n",
    "In particular, we know that if $\\lambda_i\\sim N(\\mu_i,\\sigma_i^2)$, we will have:\n",
    "\n",
    "\\begin{align}\n",
    "q\\sim N\\left(\\sum_{i=1}^Ma_i\\mu_i\\ ,\\ \\sum_{i=1}^M{a_i^2\\sigma_i^2}\\right)\n",
    "\\end{align}\n",
    "\n",
    "For simplicity, call these new mean and variance terms, $\\mu_q$ and $\\sigma_q^2$.\n",
    "\n",
    "Now let us consider the MUD point of our updated distribution. Using logarithms, we can break up our maximum estimate to look like:\n",
    "\n",
    "\\begin{align}\n",
    "\\max_{\\lambda}{\\pi^{up}(\\lambda)}&=\\max_{\\lambda}\\left\\{\\log\\left(\\pi^{init}(\\lambda)\\right)+\\log\\left(\\pi^{data}(q)\\right)-\\log\\left(\\pi^{pf}(q)\\right)\\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\max_{\\lambda}\\left\\{-(\\lambda-\\mu)^TD^{-1}(\\lambda-\\mu) - \\frac{1}{\\sigma_\\nu^2}(q-\\nu)^2+\\frac{1}{\\sigma_q^2}(q-\\mu_q)^2\\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{\\left(\\lambda^TD^{-1}\\lambda-\\mu^T D^{-1}\\lambda-\\lambda^T D^{-1}\\mu +\\mu^TD^{-1}\\mu \\right) + \\frac{1}{\\sigma_\\nu^2}(q-\\nu)^2-\\frac{1}{\\sigma_q^2}(q-\\mu_q)^2\\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{\\left(\\lambda^TD^{-1}\\lambda-2\\mu^T D^{-1}\\lambda \\right) + \\frac{1}{\\sigma_\\nu^2}(q-\\nu)^2-\\frac{1}{\\sigma_q^2}(q-\\mu_q)^2\\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{\\left(\\lambda^TD^{-1}\\lambda-2\\mu^T D^{-1}\\lambda \\right) + \\left(\\frac{1}{\\sigma_\\nu^2}-\\frac{1}{\\sigma_q^2}\\right)q^2-2\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)q+\\left(\\frac{\\nu^2}{\\sigma_\\nu^2}-\\frac{\\mu_q^2}{\\sigma_q^2}\\right) \\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{\\left(\\lambda^TD^{-1}\\lambda-2\\mu^T D^{-1}\\lambda \\right) + \\left(\\frac{1}{\\sigma_\\nu^2}-\\frac{1}{\\sigma_q^2}\\right)(a^T\\lambda)^2-2\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)(a^T\\lambda) \\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{ \\lambda^TD^{-1}\\lambda+ \\left(\\frac{1}{\\sigma_\\nu^2}-\\frac{1}{\\sigma_q^2}\\right)(a^T\\lambda)(a^T\\lambda)-2\\mu^T D^{-1}\\lambda  -2\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)(a^T\\lambda) \\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{ \\lambda^TD^{-1}\\lambda+ (\\lambda^Ta)\\left(\\frac{1}{\\sigma_\\nu^2}-\\frac{1}{\\sigma_q^2}\\right)(a^T\\lambda)-2\\mu^T D^{-1}\\lambda  -2\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)(a^T\\lambda) \\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{ \\lambda^T\\left(D^{-1}+\\left(\\frac{1}{\\sigma_\\nu^2}-\\frac{1}{\\sigma_q^2}\\right)aa^T\\right)\\lambda-2\\left[\\mu^T D^{-1}+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a^T\\right]\\lambda \\right\\} \\\\[2ex]\n",
    "%\n",
    "&=\\min_{\\lambda}\\left\\{ \\lambda^T\\left(D^{-1}+\\frac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)aa^T\\right)\\lambda-2\\left[\\mu^T D^{-1}+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a^T\\right]\\lambda \\right\\} \\\\[2ex]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the derivative we get the following:\n",
    "\n",
    "\\begin{align}\n",
    "0&=\\lambda^T\\left(D^{-1}+\\frac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)aa^T\\right)-2\\left[\\mu^T D^{-1}+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a^T\\right] \\\\[2ex]\n",
    "\\lambda^T\\left(D^{-1}+\\frac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)aa^T\\right)&= \\left[\\mu^T D^{-1}+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a^T\\right] \\\\[2ex]\n",
    "\\lambda^T&= \\left[\\mu^T D^{-1}+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a^T\\right]\\left(D^{-1}+\\frac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)aa^T\\right)^{-1} \\\\[2ex]\n",
    "\\lambda&= \\left[\\mu^T D^{-1}+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a^T\\right]^T\\left(\\left(D^{-1}+\\frac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)aa^T\\right)^{-1}\\right)^T \\\\[2ex]\n",
    "\\lambda&= \\left(\\left(D^{-1}+\\frac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)aa^T\\right)^{-1}\\right)^T\\left[(D^{-1})^T\\mu+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a\\right] \\\\[2ex]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let $A$ denote the matrix $aa^T$. This matrix is symmetric. Since $D^{-1}$ is a diagonal matrix, $D^{-1} + cA$ is symmetric. So we know its inverse will be symmetric (if its inverse exists). Thus we have:\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda&= \\left(D^{-1}+\\frac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)A\\right)^{-1}\\left[D^{-1}\\mu+\\left(\\frac{\\nu}{\\sigma_\\nu^2}-\\frac{\\mu_q}{\\sigma_q^2}\\right)a\\right] \\\\[2ex]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the inverse matrix term. This matrix will look like:\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{pmatrix}\n",
    "\\frac{1}{\\sigma_1^2} & 0 & \\ldots & 0\\\\\n",
    "0 & \\frac{1}{\\sigma_2^2} & \\ddots & 0\\\\\n",
    "\\vdots & \\ddots & \\ddots & \\vdots \\\\\n",
    "0 & \\ldots & \\ldots &  \\frac{1}{\\sigma_M^2} \\\\\n",
    "\\end{pmatrix}+c\\begin{pmatrix}\n",
    "a_1^2 & a_1a_2 & \\ldots & a_1a_M\\\\\n",
    "a_2a_1 & a_2^2 & \\ddots & a_2a_M\\\\\n",
    "\\vdots & \\ddots & \\ddots & \\vdots \\\\\n",
    "a_Ma_1 & \\ldots & \\ldots &  a_M^2 \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the equations row by row, we can rewrite the system of equations in the following way. Each $\\lambda_i$ of the MUD point should satisfy the following system of equations:\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda_i&=\\mu_i+\\dfrac{a_i^2\\sigma_i^2}{\\sigma_\\nu^2}\\cdot\\dfrac{1}{a_i}\\left[\\nu-\\sum_{j=1}^Ma_j\\lambda_j\\right]-\\dfrac{a_i^2\\sigma_i^2}{\\sigma_q^2}\\cdot\\dfrac{1}{a_i}\\left[\\mu_q-\\sum_{j=1}^Ma_j\\lambda_j\\right]\n",
    "\\end{align}\n",
    "\n",
    "First note that written in this form, $\\lambda_i$ is on both sides of the equation. However, written in this way allows the expression to be slightly more interpretable. This says something like each $\\lambda_i$ should be the initial mean $\\mu_i$ plus some corrections.\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda_i&=\\mu_i+\\dfrac{a_i^2\\sigma_i^2}{\\sigma_\\nu^2}\\cdot\\dfrac{1}{a_i}\\left[\\nu-Q(\\lambda)\\right]-\\dfrac{a_i^2\\sigma_i^2}{\\sigma_q^2}\\cdot\\dfrac{1}{a_i}\\left[Q(\\mu)-Q(\\lambda)\\right]\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a concrete example to help parse this expression. Suppose that $\\vec{a}=(3,-2)$ and $\\mu_i\\sim N(1,1)$. We can compute the push forward of this map, which will be $q\\sim N(1,13)$. \n",
    "\n",
    "Suppose we observe a distribution $\\nu\\sim N(2,3)$. Let us consider what this means for the MUD point $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the matrix algebra below\n",
    "linear_map = np.array([3,-2])\n",
    "mu, sigma_mu = np.array([1,1]), np.array([1,1])\n",
    "pf_mean, pf_var = np.dot(linear_map,mu), np.dot(linear_map**2,sigma_mu)\n",
    "obs_mean, obs_var = 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 -6]\n",
      " [-6  4]]\n"
     ]
    }
   ],
   "source": [
    "# covariance matrix D^-1\n",
    "cov_inv = np.diag(1/sigma_mu)\n",
    "matrixA = np.outer(linear_map,linear_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-hand side of matrix solve for MUD point\n",
    "left_side = cov_inv + 1/obs_var*(1-obs_var/pf_var)*matrixA\n",
    "\n",
    "# right-hand side of matrix solve for MUD point\n",
    "right_side = np.dot(cov_inv,mu) + 1/obs_var*(obs_mean-obs_var/pf_var*pf_mean)*linear_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam_MUD = np.linalg.solve(left_side,right_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.23076923  0.84615385]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(lam_MUD)\n",
    "print(np.dot(linear_map,lam_MUD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key thing to notice here is that the new point in lambda space has been adjusted in such a way that the push-forward of the MUD point is consistent with the observed maximum density point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> I made a mistake here doing this matrix algebra by hand\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda&=\\left(\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0& 1\n",
    "\\end{pmatrix}+\\dfrac{1}{\\sigma_\\nu^2}\\left(1-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\right)\\begin{pmatrix}\n",
    "9 & -6 \\\\\n",
    "-6 & 4 \\\\\n",
    "\\end{pmatrix}\\right)^{-1}\n",
    "\\left[\\begin{pmatrix}\n",
    "\\frac{\\mu_1}{\\sigma_1^2} \\\\\n",
    "\\frac{\\mu_2}{\\sigma_2^2}\n",
    "\\end{pmatrix}+\\dfrac{1}{\\sigma_\\nu^2}\\left(\\nu-\\frac{\\sigma_\\nu^2}{\\sigma_q^2}\\mu_q\\right)\\begin{pmatrix}\n",
    "3 \\\\\n",
    "-2\n",
    "\\end{pmatrix}\\right] \\\\[2ex]\n",
    "%\n",
    "&=\\left(\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0& 1\n",
    "\\end{pmatrix}+\\dfrac{1}{3}\\left(1-\\frac{3}{13}\\right)\\begin{pmatrix}\n",
    "9 & -6 \\\\\n",
    "-6 & 4 \\\\\n",
    "\\end{pmatrix}\\right)^{-1}\n",
    "\\left[\\begin{pmatrix}\n",
    "1 \\\\\n",
    "1\n",
    "\\end{pmatrix}+\\dfrac{1}{3}\\left(2-\\frac{3}{13}\\cdot1\\right)\\begin{pmatrix}\n",
    "3 \\\\\n",
    "-2\n",
    "\\end{pmatrix}\\right]\\\\[2ex]\n",
    "%\n",
    "&=\\left(\\left(\\frac{1}{13}\\right)\\begin{pmatrix}\n",
    "43 & -20 \\\\\n",
    "-20 & \\frac{79}{3} \\\\\n",
    "\\end{pmatrix}\\right)^{-1}\n",
    "\\left[\\dfrac{1}{13}\\cdot\\left(\\begin{pmatrix}\n",
    "13 \\\\\n",
    "13\n",
    "\\end{pmatrix}+\\left(\\frac{23}{3}\\right)\\begin{pmatrix}\n",
    "3 \\\\\n",
    "-2\n",
    "\\end{pmatrix}\\right)\\right]\\\\[2ex]\n",
    "%\n",
    "&=\\left(\\begin{pmatrix}\n",
    "43 & -20 \\\\\n",
    "-20 & \\frac{79}{3} \\\\\n",
    "\\end{pmatrix}\\right)^{-1}\n",
    "\\left[\\begin{pmatrix}\n",
    "39 \\\\\n",
    "-\\frac{7}{3}\n",
    "\\end{pmatrix}\\right]\\\\[2ex]\n",
    "%\n",
    "&=\\dfrac{3}{43\\cdot79-3\\cdot20^2}\\cdot\\left(\\begin{pmatrix}\n",
    "\\frac{79}{3} & 20 \\\\\n",
    "20 & 43 \\\\\n",
    "\\end{pmatrix}\\right)\n",
    "\\left[\\begin{pmatrix}\n",
    "39 \\\\\n",
    "-\\frac{7}{3}\n",
    "\\end{pmatrix}\\right]\\\\[2ex]\n",
    "%\n",
    "&=\\dfrac{3}{2197}\\cdot\\frac{1}{3}\\cdot\n",
    "\\left[\\begin{pmatrix}\n",
    "3\\cdot79\\cdot13-140 \\\\\n",
    "20\\cdot39-43\\cdot7\n",
    "\\end{pmatrix}\\right]\\\\[2ex]\n",
    "%\n",
    "&=\\dfrac{1}{2197}\\cdot\n",
    "\\left[\\begin{pmatrix}\n",
    "2941 \\\\\n",
    "479\n",
    "\\end{pmatrix}\\right]\\approx \\begin{pmatrix}\n",
    "1.34 \\\\\n",
    "0.22\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "To summarize this calculation, the new MUD point has shifted a little bit in the first coordinate, when compared to the initial distribution, and shifted a lot in the second coordinate.\n",
    "\n",
    "> reminder that the matrix algebra above is slightly incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what our derived formula for the MUD point means:\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda_i&=\\mu_i+\\dfrac{a_i^2\\sigma_i^2}{\\sigma_\\nu^2}\\cdot\\dfrac{1}{a_i}\\left[\\nu-Q(\\lambda)\\right]-\\dfrac{a_i^2\\sigma_i^2}{\\sigma_q^2}\\cdot\\dfrac{1}{a_i}\\left[Q(\\mu)-Q(\\lambda)\\right]\\\\[2ex]\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(lam_idx):\n",
    "    # given the index to compute, compute the rhs of above formula\n",
    "    pf_mud = np.dot(linear_map,lam_MUD)\n",
    "    adjust_one = linear_map[lam_idx]**2*sigma_mu[lam_idx]/obs_var*1/linear_map[lam_idx]*(obs_mean-pf_mud)\n",
    "    adjust_two = linear_map[lam_idx]**2*sigma_mu[lam_idx]/pf_var*1/linear_map[lam_idx]*(pf_mean-pf_mud)\n",
    "    \n",
    "    \n",
    "    lam_out = mu[lam_idx]+adjust_one-adjust_two\n",
    "    \n",
    "    return lam_out, adjust_one, adjust_two\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8461538461538467, 5.9211894646675012e-16, 0.15384615384615399)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, the middle term is basically zero. In other words, for the MUD point of the updated distribution, the difference between the observed data mean and the projection of the MUD is zero.\n",
    "\n",
    "So most of the adjustment to the initial mean is done through the last term. This last term is the difference between the push-forward and the projected updated point... In this case, the adjustment to the i-th $\\lambda$ value is the proportion of the i-th component, scaled by the linear map, to the total push-forward variance times the fraction of the difference between the projections. <- this is a wordy expression.\n",
    "\n",
    "Another thought: each term is like a signed measure of the distance between things in the data space.\n",
    "\n",
    "This makes me wonder if we could come up with an optimization scheme that would generalize to higher dimensions to find the MUD point. It would be a two step process: first, find a lambda which decreases the distance between $Q(\\lambda)$ and the observed maximum density point (or mean). Second step, use some variant of the formula above to adjust the proposed MUD point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
