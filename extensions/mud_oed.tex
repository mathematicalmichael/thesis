\subsection{Optimal Experimental Design Considerations}

In this section we return to the nonlinear examples presented in the previous chapter and address some choices made in how the experiment was performed.
By revisiting the examples, we demonstrate that the decisions made regarding measurement equipment and/or location have an impact on the reduction of uncertainty and accuracy of the MUD point.
Furthermore, we want to show that the choices made in the experimental design of previous examples were made for reasons of convenience of exposition.
Changing these assumptions does not later the viability of the MUD point as an alternative estimator for use parameter identification problems.
We study the impact of more precise measurement devices on the convergence rates for the parameter estimates in the appendix for the problem in \sec{ex:mud-exponential} of estimating the rate of exponential decay.
To complement these results, we show them alongside ones generated with equipment that measures at twice the temporal frequency.

We highlight how an awareness of another geometric property of QoI maps---relating to their sensitivity with respect to $\param$---can help improve the accuracy of the MUD estimate.
By placing sensors in locations which exhibit greater sensitivity to the parameter for which the SIP is solved, experimenters can achieve a considerable improvement in the precision of estimating $\paramref$ with an equal number of measurements collected.
A similar complementary problem is solved where information about the sensitivity of measurement locations is used to inform improved placement of a hundred sensors.
In this example, we walk through the sorts of analyses a modeler might conduct in order to select an experimental design through simulation and show a significant improvement in the accuracy of the MUD point.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Elliptic PDE Example}\label{sec:pde-example}
We make a slight modification to the Poisson problem from \ref{subsec:pde-example} to make it into a one-dimensional parameter identification problem.
This choice is primarily motivated by the goal of using visual aids to demonstrate slopes corresponding to different measurement locations.
We briefly summarize the experimental set-up again for the reader's convenience
Consider the following Poisson problem defined on a unit domain $\Omega$:
\begin{equation}\label{eq:pde-equation}
\begin{cases}
\hfill -\nabla \cdot \nabla u &= f \quad\text{on } \Omega \\
\hfill u &= 0 \quad\text{ on } \Gamma_T \cup \Gamma_B \\
\hfill \frac{\partial u}{\partial \mathbf{n}} &= g(x,\param) \quad\text{ on } \Gamma_L \\
\hfill \frac{\partial u}{\partial \mathbf{n}} &= 0 \quad\text{ on } \Gamma_R
\end{cases}
\end{equation}
where $(x_1, x_2) \in \Omega = (0,1)^2$, $\Gamma_T$ is the top, $\Gamma_B$ is the bottom, $\Gamma_L$ and $\Gamma_R$ left and right, respectively.
$\frac{\partial u}{\partial \mathbf{n}}$ denotes the outward normal direction.
We select $g=\param \sin(\pi x_2)$, and show the response surface for our given choice of $\param = 3$ in the left of Figure~\ref{fig:pde-response}, with darker colors representing more negative values.
Our initial density is chosen to be uniform over the interval $\Lambda = (1,5)$.
$f$ is chosen to be $10\exp\{-\frac{(x_1-0.5)^2 + (x_2 - 0.5)^2}{0.02}\}$


We are interested in demonstrating the impact of incorporating more measurements on our ability to estimate $\paramref$.
%This poses a problem for this particular experimental design since it will heavily rely on the way in which the sensor grid is indexed.
%One could place a regular grid of sensors in the interior of $\Omega$ to simulate a structured sensor array.
%However, observe that the response surface shown on the left panel of Figure~\ref{fig:pde-response} exhibit vertical symmetry about the line $x_2=0.5$ (as a result of our choice of $g$).
%For example, if the first half of indexed sensors corresponded to the bottom half of $\Omega$, the incorporation of the second half will be equivalent to having repeated observations.
%To avoid these problems, we instead simulate the sensors as being placed randomly (drawn from uniform distributions), in the interior so that index-dependence becomes irrelevant and probability theory ensures the lack of truly redundant measurement locations.
In \cite{Walsh}, the geometric quantity known as \emph{scaling}
We demonstrate how an awareness of the QoI's scaling (here, identified through visual inspection of slopes), can inform the construction of a more optimal QoI map by way of better selecting the locations of measurement devices.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Uninformed Sensor Placement}

We consider a selection of $S=1000$ measurement locations in the interior of the response surface chosen by sampling a uniform density over the set $(0.05, 0.95)^2 \subset \Omega$.
We show only the first hundred measurement locations in plots for visual clarity.
In the rightmost histogram of Figure~\ref{fig:pde-response}, we plot the data generated by each simulated sensor location, and note that many values are near zero as a result of being near boundaries or the right-side of $\Omega$.

\begin{figure}
\centering
  \includegraphics[width=0.35\linewidth]{figures/pde/pde_reference_solution}
  \includegraphics[width=0.35\linewidth]{figures/pde/pde_sensitivity_qoi}
  \includegraphics[width=0.675\linewidth]{figures/pde/pde_qoi_response}
\caption{(Left): The function response surface for $u$ solving \eqref{eq:pde-equation} with $S=100$ measurement locations highlighted in white.
The twenty most sensitive location markers are filled.
(Right): The derivative $\partial M_i / \partial \param$ is computed for the hundred measurement locations and the distribution of the resulting collection of slopes is plotted.
(Center): The values of the response surface at the hundred measurements is shown. The true parameter value $\paramref$ is highlighted with a vertical line, and the values of the response surface conditioned on $\paramref$ are used to form the histogram plotted vertically on the right. Many measurements are near zero.
}
\label{fig:pde-response}
\end{figure}

In the center panel of \ref{fig:pde-response}, we observe that some measurements are more sensitive than others (have steeper slopes).
The majority of measurements exhibit almost no sensitivity to changes in $\param$, visually represented by the density of nearly horizontal lines (slopes of zero).
However, some of the sensors have steep slopes, which suggests higher sensitivity to changes in $\param$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Informed Sensor Placement}
Instead of placing sensors throughout the square interior of $\Omega$ given by $(0.05, 0.95)^2$, we briefly consider how the convergence results would compare if the subdomain for sensors was better selected
In the left panel of Figure~\ref{fig:pde-response}, the most sensitive measurements are highlighted and appear near the left boundary.
Furthermore, the response surface exhibits horizontal symmetry, so we restrict locations to the bottom half of $\Omega$.
These two observations can inform a new bounding box for us to place sensors within.
We perform the same experiment for sensors placed in $(0.05, 0.25)\times(0.05, 0.5)$ (locations drawn from a uniform distribution over this region), and refer to this as the alternative experimental design.
The first hundred of the thousand sensor locations sampled is shown in the left panel of \ref{fig:pde-alt-response} and we can see that the most sensitive ones (highlighted) cluster towards the center of the left boundary, where the response surface is most negative.


\begin{figure}
\centering
  \includegraphics[width=0.35\linewidth]{figures/pde/pde-alt_reference_solution}
  \includegraphics[width=0.35\linewidth]{figures/pde/pde-alt_sensitivity_qoi}
  \includegraphics[width=0.675\linewidth]{figures/pde/pde-alt_qoi_response}
  \caption{The same panels as in Figure~\ref{fig:pde-response} but for the placement of sensors informed by the observations about sensitivity incorporated into the experimental design.
  The alternative placement eliminates redundancy induced by the symmetry of the response surface, and is concentrated in the regions which exhibit more sensitivity to changes in $\param$.
  As a result of these choices, we observe less measurements near zero (bottom histogram), and slopes with larger magnitude (top).
  }
\label{fig:pde-alt-response}
\end{figure}

For this alternative design, we show the sensitivity of sensors in the center of \ref{fig:pde-alt-response} and note that there are fewer sensors which exhibit low sensitivity to changes in $\paramref$ in contrast to \ref{fig:pde-response}.
The slopes are again shown in the center of the figure and exhibit a bimodal distribution with a larger portion of the measurements having slopes with magnitude 4-6 times greater than the mode in the center of \ref{fig:pde-response}.
There are also less measurements which take values near zero as well, shown in the rightmost panel of the figures.
Whereas the original design had an strong decay in its distribution of measurement values, the alternative shows a much more symmetric distribution.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Comparison of SIP Solutions with Different QoI Maps}

We are interested in knowing how the uncertainty around the parameter estimate (the MUD point) changes as we incorporate more (noisy) data.
To generate convergence plots, we solve the problem repeatedly for $S = 5, 10, 15, 20, 25, 50, 100, 250, 500, \text{ and } 1000$ and take the mean and variance of the twenty trials for each value of $S$.
Consider the convergence plots in Figure~\ref{fig:pde-convergence-obs}, which demonstrates the impact of increasing $S$ on our ability to resolve $\paramref$.

\begin{figure}
  \centering
  \includegraphics[width=0.475\linewidth]{figures/pde/pde_convergence_mud_obs_mean}
  \includegraphics[width=0.475\linewidth]{figures/pde/pde_convergence_mud_obs_var}
  \caption{Convergence of the MUD point (given $N=1E3$ model evaluations) for increasing numbers of observations for randomly placed sensors.
  We observe similar rates of convergence for both arrangements of measurement locations, with a marked improvement in both accuracy and precision when an informed placement is used.
  }
  \label{fig:pde-convergence-obs}
\end{figure}

It appears in the right half of Figure~\ref{fig:pde-convergence-obs}, that two decimal places of accuracy can be achieved with approximately $250$ samples instead of the $1000$ required in the left-half.


Similar to \ref{fig:ode-convergence-std}, we demonstrate that using more sensitive measurement equipment improves the estimation of the MUD point by considering the same choices for $\tau$, the precision of the sensors.
In Figure~\ref{fig:pde-convergence-std}, we study the impact of more precise measurement equipment on the absolute error's mean and variance.


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.475\linewidth]{figures/pde/pde_convergence_mud_std_mean}
  \includegraphics[width=0.475\linewidth]{figures/pde/pde_convergence_mud_std_var}
  \caption{Convergence of the MUD point given $N=1E4$ model evaluations for different measurement precision for randomly placed sensors, incorporating $S=100$ measurements.
  We note that the convergence rates are the same but the overall accuracy and precision improve when sensors are placed in regions of $u$ that exhibit higher sensitivity to changes in $\param$.
  }
  \label{fig:pde-convergence-std}
\end{figure}


The convergence results for the original experimental design demonstrate that even randomly placed sensors in the interior of $\Omega$ are suitable for parameter estimation.
However, when we considered sensors that were placed with considerations of knowing the family of curves to which $g$ belonged, we were able to extract much more information from our measurement equipment by placing sensors in different locations.
Using our alternative experimental design, we saw a reduction of uncertainty that was tangible in both Figures~ \ref{fig:pde-convergence-obs} and \ref{fig:pde-convergence-std}, represented by the persistent vertical displacement between the regression lines for convergence.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Concluding Remarks for Examples}

These examples demonstrate that Data--Consistent Inversion can be used for parameter identification as a viable alternative to existing methods.
The problems in this section have involved one-dimensional output spaces, and solely demonstrate one method by which measurements can be transformed into a QoI map.
The problems have also involved one-dimensional parameter spaces, limiting the useful dimension of the QoI map we construct.
We address these concerns in the next section by extending the previous (PDE) example to a vector-valued analogue with the original experimental design for collecting measurements in $(0.05, 0.95)^2$.

We point out that incorporating available observations as we have done in the previous two examples leaves the output space scalar-valued.
As the number of parameters grows, this output dimension resulting from such an approach effectively stays fixed.
These situations are particularly when the DCI approach becomes advantageous over other methods, as it is less sensitive to mistakes in modeling assumptions than other methods for solving inverse problems as we saw with the linear examples in ch4 [TK - refer back to section 4 and 6].
One can incorporate a much wider variety of prior beliefs about the relative likelihoods of parameters before data is collected without compromising predictive error.
The DCI approach guarantees that the functional defined (for us, the weighted mean error) will remain accurate in spite of any encoded assumptions that are somehow at odds with data that is subsequently collected.
